# Inclusive Avatar Design Guidelines
Kexin Zhang<sup>1</sup>, Edward Scott Spencer Jr.<sup>2</sup>, Abijith Manikandan<sup>2</sup>, Andric Li<sup>1</sup>, Ang Li<sup>1</sup>, Yaxing Yao<sup>2</sup>, Yuhang Zhao<sup>1</sup>

<sup>1</sup>University of Wisconsin-Madison, <sup>2</sup>Virginia Tech

## G0. Support disability representation in social VR avatars [1, 2]
Approximately 1.3 billion people experience significant disability, representing about 16% of the global population. 


## 1.  Avatar Body Appearance
### 1.1. Support disability representation in social VR avatars.

Social VR avatars should let users freely present their disabilities. Like any other user groups, people with disabilities want to present their disability identity in social VR. However, they often can’t find readily available options to do so. Developers and designers should include more avatar features that represent multiple disabilities, such as offering different types of assistive devices like prosthetics for users to easily add on to their avatars, or allowing self-uploaded contents for creative and individualized disability representation.

*“I think the biggest thing for me is the flexibility and the freedom to choose [how I can represent myself.] I would like to represent myself [in social VR] as an accurate reflection of what I look like. For what I've seen online, there is no standard option in the avatar creation [to represent my prosthesis]. I think that would be great to see if such a thing existed.”*
<p align="right">– an amputee</p>

*“[I want to] artistically represent my disability, [for example,] I had a circle over one eye [to symbolize that] ‘I'm looking through a tunnel,’ and then having a tape over this eye.”*
<p align="right">– a person with low vision</p>

<ins>Example:</ins>
Avatar system that provides hearing devices for disability representation[^1].

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G1.1.jpg" alt="G1.1. Example" width="220">

[^1]: Meta avatars. https://www.meta.com/avatars/ 


### 1.2. Default to a full-body avatar to enable the representation of a broad range of disabilities across different body parts.

Different disabilities may affect or be reflected in different body parts. It is thus important to offer full-body avatars to enable a wide range of disability representation options. For example, for users with lower limb disabilities, avatar templates which include further customization of the lower body would be important to present their disabilities (e.g., wearing a prosthetic leg).  Moreover, a full-body avatar provides more space to demonstrate the lived experiences of people with disabilities, e.g., how a person with visual impairments navigates the environment.

*“People can only get my whole disability identity with the full body.”*
<p align="right">– a person with cerebral palsy</p>

*“I prefer a full-body avatar, because [it shows] how [people with disabilities] navigate the pathway, how they move the hands and the fingers, and how they read braille. Everything can be oriented to the people.”*
<p align="right">– a person with visual impairment</p>

<ins>Example:</ins>
A full-body avatar with a prosthetic left foreleg.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G1.2.png" alt="G1.2. Example" width="220">


### 1.3. Enable customization of each body part instead of non-adjustable predefined sets.

Providing only avatars with “standard” body compositions prevents people with bodily differences from representing themselves accurately. Avatar platforms should allow the customization of each body part of an avatar. For example, avatar platforms should offer options to customize the presence, length, and strength of each limb; and users can select their preferred colors for various avatar components (e.g., eye color, hair color, or skin color). Asymmetrical design options of body parts (e.g., eyes, ears) should also be available. For example, allowing users to select the size and detailed look of each eyeball to reflect disabilities such as strabismus. 

*“It would be important to be able to customize each individual portion of the body. Right now, if you select the bigger one [for your] shoulders, it makes everything bigger. But that's not the case. [It would be better] if you could do, [for example,] the left arm, the right arm, even elbows, your stomach, chest, and neck, like all the different things.”*
<p align="right">– a person with mobility disabilities and mental health conditions</p>

*“I have a limb difference, [and I am] a left forearm amputation. So I would really like to see characters where maybe they don't have two long arms, but they have one long standard arm and one shorter [arm], like to the elbow. Or even if they do have two long arms, but one of them doesn't have a hand, or just one round-off around the wrist [...] instead of extending completely with a five-fingered hand.”*
<p align="right">– an amputee</p>

*“I have one eye that's in a completely different shape than the other. So I think being able to customize your eyes to two different shapes should reflect what is actually going on on your face. Now you can only pick one set.”*
<p align="right">– a person with visual and mobility impairments</p>

<ins>Example:</ins>
Options that can customize the size of each eye.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G1.3.gif" alt="G1.3. Example" width="220">


### 1.4. Prioritize human avatars to emphasize the “humanity” rather than the “disability” aspect in disability representation. 

People with disabilities often face misconceptions that they are either ‘superheroes’ or ‘tragic’, which reduce individuals to their disability label rather than seeing them as whole persons. To avoid such misconceptions, avatars should have human-like models to represent disability as an integral part of personal identities, which often intersect with other identities such as race and gender. People with disabilities also reported feeling more connected to humanoid avatars when representing personal identities in social VR.

*“Humanoid avatars show me as a whole person. I identify as a black woman with a disability, and that's really important when discussing a personal identity, because when describing somebody, you wouldn't just say, ‘Oh, they have a disability,’ instead you would say, ‘Oh, they're non-binary or female, and they're African American or Caucasian, and they have a disability.’ They all go together.”* 
<p align="right">– a person with cerebral palsy</p>

<ins>Example:</ins>
VALID validated avatar library (left)[^2] and Ready Player Me avatar (right)[^3] present human avatars that can show intersecting identities of disabilities, race, and gender. 

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G1.4.png" alt="G1.4. Example" width="290" height="150">

[^2]: VALID validated avatar library. https://research.google/blog/valid-a-perceptually-validated-virtual-avatar-library-for-inclusion-and-diversity/ 

[^3]: Ready Player Me avatar. https://readyplayer.me/ 


### 1.5. Provide non-human avatar options to free users from social stigma in real life. 

People with disabilities often face judgment based on their physical differences in real life. Avatars with non-human forms, such as robots and animals, can potentially lower others’ expectations of “typical” appearance and behaviors, freeing people with disabilities from societal judgements and stigma often associated with disabilities. 

*"I think [non-human avatars] hide more of my real disabilities, like being the opposite of showing off my disabilities."* 
<p align="right">– a person with cerebral palsy</p>

*"It feels like people's expectations of how neurotypical I'm gonna seem are lowered if I'm a robot or just a non-human avatar."*
<p align="right">– a person with mental health conditions</p>

<ins>Example:</ins>
A robotic avatar representing left forearm amputation[^4].

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G1.5.png" alt="G1.5. Example" width="220">

[^4]: Behance. https://www.behance.net/gallery/81759323/Low-Poly-Destructible-Robot


## 2. Avatar Body Dynamics: Facial Expression, Posture, and Body Motion
### 2.1. Allow the simulation of behavioral characteristics related to disability only based on users’ preference.

Representing the realistic movements of people with disabilities on avatars could make them feel more connected with their avatars and immersed in the VR experience. For instance, a person with Tourette’s Syndrome may have tics on their face and prefer showing them authentically via their avatar design. However, the realistic simulation of disability-related behaviors on avatars may also reinforce the stereotype people with disabilities experience in real life. For example, for people who experience unconventional or involuntary movements (e.g., stumbling, nervous tics), directly simulating these movements can be disrespectful and should be avoided. Developers should be careful not to create simulations that may cause misunderstanding or reinforce stereotypes, and should only do so if users prefer it. 

*“I think it would be cool if you could choose to have [the movement to be reflected]. But I also think that it is a very fine line between inclusion and offensive imitation.”* 
<p align="right">– a person with mobility disabilities</p>

*“The way I move authentically is kind of jaggy, and I swerve. People asked me if I'm drunk all the time. So you know I'd like to go as quickly as I can in a smooth way [...] even though that's not authentic."* 
<p align="right">– a person with mobility disabilities</p>

*“I have nervous tics that are kind of full body shutters. When I do those in real life, the VR avatar does often follow those, which makes it hard for people to figure out if it's glitching out or something. So finding ways to make those smoother and more reflective of reality, rather than like, 'is this internet thing? or what's happening?'”* 
<p align="right">– a person with mental health conditions</p>

<ins>Example:</ins>
Avatar can show motor tics (left) or not (right) based on the user's preference.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G2.1.png" alt="G2.1. Example" width="320" height="150">


### 2.2. Enable expressive facial animations that deliver a spectrum of emotions.

For people with invisible disabilities, enabling expressive facial expressions is critical because their conditions (e.g., depression, bipolar disorder, and anxiety) often surface through their emotions. It’s especially important to include expressions representing both positive and negative emotions (e.g., sadness, anxiety, or even crying) to portray the user’s mental status visually and demonstrate what they are really feeling.  

*“Depression is part of my life, and I think avatars need to spend a little more time not looking so happy all the time, which is not an option there. [The avatars] are always smiling. I think that needs to be a little bit more [variations].”*
<p align="right">– A person with severe depression</p>

*“When representing depression, the facial expression is more sad or in thought. And then when having ADHD moments, [the avatar] being more excited or manic.”*
<p align="right">– A person with depression and ADHD</p>

<ins>Example:</ins>
Avatar shows diverse emotions, including anxiety (left), sadness (middle), and happiness (right).

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G2.2.png" alt="G2.2. Example" width="320" height="150">


### 2.3. Prioritize equitable capability and performance of avatar over the authentic behaviors of people with disabilities.

While people with disabilities should have the option to reflect their unique movements through their avatars if they so choose (e.g., limp while walking), these movement characteristics should not impact the capabilities or performance of the avatar, thus creating a fair user experience for all. For example, the movement speed of an avatar in a wheelchair should be the same as the walking speed of other avatars. 

*“I walk with a slight limp, [but] I don't think I need the actual movement [on avatars] to reflect how [fast] I walk. [Because] when I use games, I see the movement aspect more of a practicality than part of the game [...] I think having a limp would be cool, but I wouldn't want to be slower than [other avatars]. I wouldn't want to have a maximum speed, because I chose to have a limp earlier in the avatar making process."* 
<p align="right">– a person with mobility disabilities</p>

*“Being able to just keep up with peers’ [avatars], pace-wise, would be the most important thing.”* 
<p align="right">– a person with mobility disabilities</p>

<ins>Example:</ins>
The avatar with the wheelchair moves at the same speed as the avatar without the wheelchair.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G2.3.gif" alt="G2.3. Example" width="250">


### 2.4. Leverage avatar posture and motion to demonstrate the lived experiences of people with disabilities. 

Beyond presenting the disability in itself, users also want to reflect their lived experience with disabilities via avatars through avatar posture or motion for awareness purposes. For example, a low vision person may adopt a unique head position, turning their head slightly to one side to see with their better eye, or a blind person may bend their body forwards in an attempt to better capture sound; representing these behaviors on avatars helps other users acknowledge that these mannerisms are not a sign of disinterest in social interactions but rather a means to better engage in conversations.

*“[My] vision is directed at one angle. So my head is turned lightly, because I'm not looking at people directly all the time.”* 
<p align="right">– a low vision person </p>

*“The visually impaired people are not standing strictly. Slightly bending down towards the front is a common feature of the visually impaired people if they have visual disability by birth. Because instead of looking at the person who is speaking, they take their ears nearby to the place where the sound is coming from, instead of [looking at the speaker's] face. This gives some wrong impressions to the people that the visually impaired people have not given attention to the speakers. That is not the real story.”*
<p align="right">– a blind person </p>

*“Typically you're in a VR situation, and you're facing somebody and focused on looking at one another. [But] a lot of times when I look at somebody, my eyes are not looking at their face all the time. So I think having the ability to look at other places while I'm facing somebody would be important to me. Because that helps me represent the way that I interact with people.”* 
<p align="right">– a person with ADHD</p>

<ins>Example:</ins>
The avatar representing a low vision person (left) shows a different posture than the avatar representing a sighted person (right) in a conversation. 

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G2.4.png" alt="G2.4. Example" width="340" height="130">



## 3. Assistive Technology Design
### 3.1. Offer various types of assistive technology to cover a wide range of disabilities. 

People with disabilities see their assistive technologies as an extension of their body. An avatar which features the specific assistive technology they use is important because it helps represent their identities and offers a feeling of empowerment, inclusion, and immersion. Avatar platforms should therefore offer assistive technologies that are commonly used by people with different types of disabilities, including but not limited to mobility aids (e.g., wheelchair, cane, crutches, prosthetic limbs), hearing devices (e.g., hearing aids, cochlear implants), visual aids (e.g., glasses), and medical devices (e.g., insulin pumps, ventilator tubing). 

*“For people in wheelchairs, our wheelchair is an extension of our body [...] we view it emotionally as an extension of ourselves, and it gives us our independence.”*
<p align="right">– a wheelchair user</p>

*“I think being able to represent myself in a way that I can choose is empowering to me, and having the option of [adding] a mobility aid on my avatar feels empowering.”* 
<p align="right">– a walking cane user</p>

*“I think that the wheelchair would be a good addition to it. Being able to move it in the VR world gives me a sense that I'm a part of this VR world too.”*
<p align="right">– a wheelchair user</p>

<ins>Example:</ins>
Offer multiple types of mobility aids, such as crutches (left)[^5] and prosthetic limb (right)[^6]. 

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.1.png" alt="G3.1. Example" width="320" height="120">

[^5]: Sketchfab crutches. https://sketchfab.com/3d-models/crutches-d115c17f138d4dea941bbb0de181c6c7
[^6]: Sketchfab robotic prosthetic arm.  https://sketchfab.com/3d-models/robotic-prosthetic-arm-43b482c8526f45709b56434924dc4d3c

### 3.2. Allow detailed customization of assistive technology for personalized disability representation.

With assistive technology being an extension of the user’s body, being able to customize the design of the assistive technology is as important as customizing the avatar’s appearance. A spectrum of options should be available, rather than a simple default choice. For example, wheelchair options should include both manual and powered models. In addition, customizing the aesthetics of the assistive technology, such as adjusting the color or adding personalized decoration (e.g., stickers on wheelchairs), offers a unique way for people with disabilities to express their personalities. 

*“[Now] you either have a wheelchair or no wheelchair, but you can't customize the type, shape, or any various add-ons. Like is it motorized [wheelchair]? Is it like a manual one? So I think having the ability to choose what additional features you'd like to add would be really nice.”* 
<p align="right">– prosthetic limb user</p>

*“Making some more customizations in the wheelchair. Because again, [it’s] in the same way that you make customizations for eye color, nose shape, [and] all those things.”* 
<p align="right">– a person with mobility disabilities</p>

<ins>Example:</ins>
Users can adjust the color of the power wheelchair, like the cushions, wheels, and chassis cover.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.2.png" alt="G3.2. Example" width="320" height="160">


### 3.3. Provide high-quality, realistic simulation of assistive technology to present disability respectfully and avoid misuse.

As an emerging social platform, it’s not uncommon to see some avatars with disability features (e.g., avatars on wheelchairs). However, these avatars are usually designed in a low-quality or stereotypical manner, which leads to the misuse of assistive technology, such as trolling or memeing, perpetuating stigma toward people with disabilities. To represent disability respectfully, assistive technology should be designed and simulated authentically. It should be high in quality and contain sufficient details. For example, the design of a white cane for people with low vision should follow the standardized color selection for such walking aids. 

*“[I’ve seen] really poor representation [of wheelchairs]. They're usually joke avatars or meme avatars that have wheelchairs.”*
<p align="right">– a person with mental health conditions</p>

*“​​So while walking, the tip of the white cane should move like the pendulum motion, [moving] forth and back in that way.”* 
<p align="right">– a person who is blind and low vision</p>

<ins>Example:</ins>
The low-fidelity wheelchair (left)[^7] might be misperceived as mocking. Instead, the wheelchair should be designed with high-fidelity and realistic details (right) to represent disability respectfully.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.3.png" alt="G3.3. Example" width="320" height="160">

[^7]: Sketchfab wheelchair model. https://sketchfab.com/3d-models/wheelchair-json-08f4dafe05304cb785d9bcf980a44bc5 


### 3.4. Focus on simulating assistive technologies that empower people with disabilities, rather than those that highlight their challenges.

Using assistive technology is often associated with the stereotype of being dependent. For example, the media often misrepresents people with mobility disabilities by showing them sitting on hospital-style wheelchairs, which leaves an impression that they need to be taken care of by someone else. To combat the stereotypes, the representation of assistive technology should demonstrate how people with disabilities achieve independence through the use of assistive technology. An example of how this could be achieved would be avoiding hospital-style wheelchairs and removing the handles on a manual wheelchair to signify independence. 

*“Most of the representations that we see in fiction, video games and TV, they always use hospital chairs, which is not practical. Basically, no actual disabled person uses a hospital chair in real life [...] on a hospital wheelchair, there are armrests and big push handles, because it's usually built for somebody to push you. However, a manual wheelchair is designed for you to push yourself.”* 
<p align="right">– a wheelchair user</p>

*“I'm stating that independence [achieved through wheelchair]. I'm solidly myself, and I don't need another person. This is a big deal in our community [...]  we’re not going to want push handles [...] I'm sitting up tall. I'm here.”*
<p align="right">– a wheelchair user</p>

*“It's important to me that it doesn't look like I'm ready to be pushed by someone else.”* 
<p align="right">– a wheelchair user</p>

<ins>Example:</ins>
The manual wheelchair has no handles, demonstrating that it’s designed for users who want to navigate independently instead of being pushed. 

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.4.png" alt="G3.4. Example" width="220">


### 3.5. Demonstrate the liveliness of people with disabilities through interaction with assistive technology.

In addition to the visual details, showing how people with disabilities actively control and interact with the assistive technology is another way to demonstrate independence. For example, the avatar should demonstrate circular arm movement when pushing a manual wheelchair, and the wheels should roll. Additionally, the proper posture of the avatar sitting up tall in a wheelchair also reflects the liveliness and capability of the user.

*“I think having the option to roll [wheelchair] instead of walking would be good. I’ve seen some 3D models of wheelchair users in video games, and their arms don't move while they're rolling, which is really weird to me. Because I push myself with my hands.”* 
<p align="right">– a person with mobility disabilities</p>

*“You would lean forward on the joystick, and the wheels would be moving. Or if you go backwards, you’d be pulling [the joystick] back and it would move backwards.”*
<p align="right">– a person with mobility disabilities</p>

<ins>Example:</ins>
Avatar controls the manual wheelchair through pushing.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.5.gif" alt="G3.5. Example" width="220">


### 3.6. Avoid overshadowing the avatar body with the assistive technology.

When representing disability through assistive technology, the focus should always be on the avatar’s body rather than its assistive technology. In practice, the size of assistive technology should not dominate the avatar body but rather fit the body size. Developers should make sure users can easily adjust the size of assistive technology to fit the avatar's body size well.

*“The wheelchair is not the focus of the image. [But] the avatar is having a good time, and that's the focus of the image.”*
<p align="right">– a wheelchair user</p>

*“I think that having the option to actually make the chair larger or smaller, depending on how large or small your avatar is, is a good detail. Because sometimes wheelchairs don't fit you. I have encountered 3d models where the wheelchair is so big and the person sitting in it is so small, and it just doesn't look right.”*
<p align="right">– a wheelchair user</p>

<ins>Example:</ins>
Users can change the size of assistive technology to match with their avatar size.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G3.6.gif" alt="G3.6. Example" width="220">



## 4. Peripherals around Avatars
### 4.1. Provide suitable icons, logos, and slogans that represent disability communities. 

Including representative symbols of disability communities helps people to express their disabilities in a symbolic way. These symbols can be featured on avatar’s clothing and accessories, or elsewhere. Examples of symbols include the rainbow and infinity logo that are widely recognized within the autism community, and sunflowers to symbolize hidden disabilities. 

*“Now we have like characters who can wear T-shirts with the LGBTQ plus pride flag on it, or they can wear T-shirts that have ‘Black Lives Matters.’ So having equivalent things for disability would be awesome.”*
<p align="right">– a person with mobility disabilities</p>

*“It’s about hidden disabilities, and you can get sunflower lanyards, which is a way of saying ‘I'm disabled, but you can't tell.’ So if the character looks like they're walking and they've got sparkly, flowy sunflowers behind them, [that] would be cool.”*
<p align="right">– a person with mobility disabilities</p>

<ins>Example:</ins>
An avatar wearing a T-shirt with a rainbow and infinity symbol to represent the autism spectrum disorder community. 

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G4.1.png" alt="G4.1. Example" width="220">


### 4.2. Leverage spaces beyond the avatar body to present disabilities.

The space surrounding an avatar offers opportunities for people with disabilities, especially those with invisible ones, to creatively represent themselves. For example, people with depression want to add visual indicators in the avatar's background to show their current conditions (i.e., a cloudy and rainy background to symbolize a user feeling depressed at the moment). Another example would involve using icons, such as a battery symbol above the avatar's head, which would change levels depending on the user’s mood. 

*“I’d imagine there were things around me, like a dark gray cloud or it's raining in the background and being right above you. And everywhere you go, it's right there.”* 
<p align="right">– a person with ADHD and depression</p>

*“My energy levels can fluctuate just a lot. Someday, I may have a little bit of energy, and the next day I may have a lot of energy, and that could actually change within a matter of hours. So the idea that I have is a battery symbol that I could adjust the battery level shown on that to show you how much energy that I have to spend. It's a signal to my friends that ‘hey, my battery's low, I may sound really tired right? I'm okay, I just have low energy.’ [Other times] I could turn my battery all the way up and be like, ‘Hey, let's see, we can do something a little bit more active​​.’”*
<p align="right">– a person with neurodivergence and low vision</p>

<ins>Example:</ins>
An avatar with a floating bubble overhead, showing a level of social energy.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G4.2.png" alt="G4.2. Example" width="320" height="150">


## 5. Design of Avatar Customization and Control Interface
### 5.1. Integrate disability features across the avatar customization process, rather than gathering them in a specialized category.

Putting all disability-related features in one category is a form of exclusion. It makes people with disabilities feel they are using features intentionally designed as “for disabilities”, which sets them apart from other users. Instead, disability-related features should be naturally embedded in all aspects of the avatar customization interface. For example, including assistive technologies like walking canes alongside other accessories like hats or glasses rather than a special ‘disability representation’ section, could mitigate this problem.  

*“Have those [disability representation] options in a variety of places, not like to create a disabled avatar, [you need to] go 13 levels down to the left, and [there’s a] submenu for that. Just make it integral to what you're designing, instead of making it like, ‘you gotta go on the short bus to get to the avatars for people with disabilities. Make it a part of everything else. Don't isolate it.”*
<p align="right">– a person who is blind</p>

*“You can include a cane with the accessories tab instead of having a disabled tab over there…that can be kind of ostracizing. Just treating them as neutral instead of either a burden to have to design or something you get to feel really special for designing.”* 
<p align="right">– a person with mental health conditions</p>

<ins>Example:</ins>
Walking canes and wheelchairs are included under the accessory category along with items like glasses, hats and bags.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G5.1.png" alt="G5.1. Example" width="330" height="350">


### 5.2. Use input controls that offer precise adjustments whenever possible. 

A common problem with current avatar customization interfaces is not being able to find customization options which accurately represent people’s disabilities. An example of addressing this issue would be to give users the ability to modify the exact length of a missing or impaired limb. Developers and designers should use input controls that offer a continuous range of options for people to flexibly represent themselves. For example, sliders and knobs are continuous input controls that enable fine-grained customizations. 

*“[I prefer] the sliding scale … [so] you can really change it on a very particular level.”* 
<p align="right">– a person with autism</p>

*“It's better to have a spectrum of choices, or even a slider like for people to change your nuanced level.”* 
<p align="right">– a person with mobility disabilities</p>

<ins>Example:</ins>
Offer a slider to change the length of limbs.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G5.2.gif" alt="G5.2. Example" width="220">


### 5.3. Offer an easy control to turn on and off disability features.

People don’t want to be defined by their disability and show their disability all the time. The disclosure of disability often depends on social contexts. For example, people might not want to disclose their disabilities when they are surrounded by strangers or unfriendly users. For this reason, social VR platforms should allow users to easily toggle on and off the disability-related features as needed. For example, implementing a shortcut that can instantly remove disability features from an avatar would address this issue.

*“If I'm in a very comfortable setting, and [people are] accepting, I'm going to come in there [as an avatar with disability-related features]. [At the same time,] it's important to have that [avatar with disability-related features] to be changed, where I can still have how my body shows up in the world but not necessarily with the wheelchair. That’s important, because although I have a disability and I'm comfortable with it, it is not the most important thing to me. So sometimes I might not want to lead with that, especially when you have physical disabilities that people can see, where you encounter a lot in the world where you have no control over how people see you right away.”* 
<p align="right">– a person with mobility disability</p>

<ins>Example:</ins>
Users should be able to turn disability-related features on and off with a single click.

<img src="https://github.com/MadisonAbilityLab/Inclusive-Avatar-Guidelines-and-Library/blob/main/guidelines_image/G5.3.gif" alt="G5.2. Example" width="370" height="130">


## References 
<a id="1">[1]</a> 
Ria J. Gualano, Lucy Jiang, Kexin Zhang, Tanisha Shende, Andrea Stevenson Won, and Shiri Azenkot. 2024. “I Try to Represent Myself as I Am”: Self-Presentation Preferences of People with Invisible Disabilities through Embodied Social VR Avatars. In Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility (St. John’s, NL, Canada) (ASSETS ’24). Association for Computing Machinery, New York, NY, USA, Article 72, 15 pages. https://doi.org/10.1145/3663548.3675620

<a id="1">[2]</a> 
Kexin Zhang, Elmira Deldari, Zhicong Lu, Yaxing Yao, and Yuhang Zhao. 2022. “It’s Just Part of Me:” Understanding Avatar Diversity and Self-presentation of People with Disabilities in Social Virtual Reality. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS ’22). Association for Computing Machinery, New York, NY, USA, Article 4, 16 pages. https://doi.org/10.1145/3517428.3544829
